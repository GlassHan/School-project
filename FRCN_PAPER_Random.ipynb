{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90fc2b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils import data\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "import time\n",
    "import utils_ObjectDetection as utils\n",
    "from torch.utils.data import BatchSampler,SequentialSampler,RandomSampler\n",
    "import torch.nn as nn\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import math \n",
    "import ITB_RECALL_PRECISION_F1 as rp_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e82ac59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model, img, threshold):\n",
    "    model.eval()\n",
    "    preds = model(img)\n",
    "    for id in range(len(preds)) :\n",
    "        idx_list = []\n",
    "\n",
    "        for idx, score in enumerate(preds[id]['scores']) :\n",
    "            \n",
    "            if score > threshold : \n",
    "                idx_list.append(idx)\n",
    "\n",
    "        preds[id]['boxes'] = preds[id]['boxes'][idx_list]\n",
    "        preds[id]['labels'] = preds[id]['labels'][idx_list]\n",
    "        preds[id]['scores'] = preds[id]['scores'][idx_list]\n",
    "\n",
    "    return preds\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "def get_transform():\n",
    "    custom_transforms = []\n",
    "    custom_transforms.append(torchvision.transforms.ToTensor())\n",
    "    return torchvision.transforms.Compose(custom_transforms)\n",
    "\n",
    "\n",
    "def get_model_instance_segmentation(num_classes,train_layer):\n",
    "    # load an instance segmentation model pre-trained pre-trained on COCO\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True,trainable_backbone_layers=train_layer)\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    return model\n",
    "\n",
    "def plot_image_from_output(img, annotation):\n",
    "    \n",
    "    img = img.cpu().permute(1,2,0)\n",
    "    \n",
    "    fig,ax = plt.subplots(figsize=(20, 10))\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    for idx in range(len(annotation[\"boxes\"])):\n",
    "        xmin, ymin, xmax, ymax = annotation[\"boxes\"][idx]\n",
    "\n",
    "        if annotation['labels'][idx] == 1 :\n",
    "            rect = patches.Rectangle((xmin,ymin),(xmax-xmin),(ymax-ymin),linewidth=1,edgecolor='b',facecolor='none')\n",
    "        \n",
    "        elif annotation['labels'][idx] == 2 :\n",
    "            \n",
    "            rect = patches.Rectangle((xmin,ymin),(xmax-xmin),(ymax-ymin),linewidth=1,edgecolor='g',facecolor='none')\n",
    "            \n",
    "        elif annotation['labels'][idx] == 3 :\n",
    "        \n",
    "            rect = patches.Rectangle((xmin,ymin),(xmax-xmin),(ymax-ymin),linewidth=1,edgecolor='orange',facecolor='none')\n",
    "        else:\n",
    "            rect = patches.Rectangle((xmin,ymin),(xmax-xmin),(ymax-ymin),linewidth=1,edgecolor='r',facecolor='none')\n",
    "\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3732c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class simpleDataset(object):\n",
    "\n",
    "\n",
    "    def __init__(self, dataset,resize,color, img_foler_path,transforms=None):\n",
    "    #             self.root = root\n",
    "            self.transforms = transforms\n",
    "            self.adnoc = dataset\n",
    "            self.ids = dataset.index\n",
    "            self. filenames=dataset['path'].to_list()\n",
    "            self.resize =resize\n",
    "            self.color=color\n",
    "            self.img_foler_path=img_foler_path\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Own coco file\n",
    "        adnoc_df = self.adnoc\n",
    "        # Image ID ,폴더에서 index번째 \n",
    "        img_id = self.ids[index]\n",
    "\n",
    "       # List: get annotation id from coco, index번째 annotation가져오기 [[1,2,3,4],[5,6,7,8]]\n",
    "        annotation = adnoc_df['box'][img_id]\n",
    "\n",
    "\n",
    "        # open the input image, 흑백=L , 단색=1\n",
    "        img= Image.open(str(self.img_foler_path)+str(adnoc_df.loc[img_id]['path'])).convert(self.color)\n",
    "        img= img.resize((int(img.width / self.resize), int(img.height / self.resize)))\n",
    "      \n",
    "        # number of objects in the image\n",
    "        num_objs = len(annotation)\n",
    "\n",
    "        # Bounding boxes for objects\n",
    "        # In coco format, bbox = [xmin, ymin, width, height]\n",
    "        # In pytorch, the input should be [xmin, ymin, xmax, ymax]\n",
    "        boxes = []\n",
    "        areas = []\n",
    "        label = []\n",
    "        for i in range(num_objs):\n",
    "\n",
    "            xmin = annotation[i][0]\n",
    "            ymin = annotation[i][1]\n",
    "            xmax = xmin + annotation[i][2]\n",
    "            ymax = ymin + annotation[i][3]\n",
    "            l=annotation[i][4]\n",
    "            area=annotation[i][2]*annotation[i][3]\n",
    "\n",
    "            boxes.append([xmin/self.resize, ymin/self.resize, xmax/self.resize, ymax/self.resize])\n",
    "          \n",
    "            label.append(l)\n",
    "            areas.append(area)\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        #areas= box size = width * height\n",
    "        areas = torch.as_tensor(areas, dtype=torch.float32)\n",
    "\n",
    "        # Labels (In my case, I only one class: target class or background)\n",
    "        labels = torch.as_tensor(label, dtype=torch.int64)\n",
    "\n",
    "        # Tensorise img_id\n",
    "        img_id = torch.tensor([img_id])\n",
    "\n",
    "        # Iscrowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        # Annotation is in dictionary format\n",
    "        my_annotation = {}\n",
    "        my_annotation[\"boxes\"] = boxes\n",
    "        my_annotation[\"labels\"] = labels\n",
    "        my_annotation[\"image_id\"] = img_id\n",
    "        my_annotation[\"area\"] = areas\n",
    "        my_annotation[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, my_annotation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "\n",
    "\n",
    "    # the total number of samples (optional)\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31ccc9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_RPA(test_data_loader,model,param,iteration):\n",
    "    \n",
    "    model = get_model_instance_segmentation(4,5)\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(param))\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    confi=[0.5]\n",
    "    RECALL=[]\n",
    "    PRECISION=[]\n",
    "    F1_SCORE=[]\n",
    "    for c in confi: \n",
    "        labels = []\n",
    "        preds_adj_all = []\n",
    "        annot_all = []\n",
    "        print('confidence=',c)\n",
    "        for im, annot in tqdm(test_data_loader, position = 0, leave = True):\n",
    "            im = list(img.to(device) for img in im)\n",
    "\n",
    "   \n",
    "            for t in annot:\n",
    "                labels += t['labels']\n",
    "\n",
    "            with torch.no_grad():\n",
    "                preds_adj = make_prediction(model, im, c)\n",
    "                preds_adj = [{k: v.to(torch.device('cpu')) for k, v in t.items()} for t in preds_adj]\n",
    "                preds_adj_all.append(preds_adj)\n",
    "                annot_all.append(annot)\n",
    "\n",
    "        #precision=0.2\n",
    "        iou_threds=0.5\n",
    "        pr_f1=rp_f1.Precision_Recall_F1(iou_threds,preds_adj_all,annot_all)\n",
    "      \n",
    "        \n",
    "        recall=pr_f1.RECALL()\n",
    "        precision=pr_f1.PRECISION()\n",
    "        f1_score=pr_f1.F1_SCORE()\n",
    "      \n",
    "\n",
    "        RECALL.append(recall)\n",
    "        PRECISION.append(precision)\n",
    "        F1_SCORE.append(f1_score)\n",
    "    \n",
    "    \n",
    "    print(RECALL,'\\n',PRECISION,'\\n',F1_SCORE)\n",
    "    result=pd.DataFrame(confi,columns=['confidence'])\n",
    "    result['iteration']=iteration\n",
    "    result['recall']=[RECALL]\n",
    "    result['precision']=[PRECISION]\n",
    "    result['f1_form']=[F1_SCORE]\n",
    "    \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "862ae8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling(train,batch):\n",
    "   \n",
    "    sampled=train.sample(n=batch,random_state=42)\n",
    "    train_rest=train.drop(sampled.index)\n",
    "        \n",
    "    return sampled,train_rest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41e961dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load(data):\n",
    " \n",
    "    # create own Dataset\n",
    "    dataset = simpleDataset(dataset=data,\n",
    "                                  resize=4,\n",
    "                                  color='L',\n",
    "                                  img_foler_path='D:/OBJ_PAPER/Data/itb_p_500/',\n",
    "                                  transforms=get_transform())\n",
    "\n",
    "\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=0,\n",
    "                                          collate_fn=collate_fn)\n",
    "\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72b72ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='D:/OBJ_PAPER/Data/3_fold_cv/'\n",
    "\n",
    "train1=pd.read_pickle(data_path+'train1.pkl')\n",
    "train2=pd.read_pickle(data_path+'train2.pkl')\n",
    "train3=pd.read_pickle(data_path+'train3.pkl')\n",
    "\n",
    "valid1=pd.read_pickle(data_path+'valid1.pkl')\n",
    "valid2=pd.read_pickle(data_path+'valid2.pkl')\n",
    "valid3=pd.read_pickle(data_path+'valid3.pkl')\n",
    "\n",
    "test=pd.read_pickle(data_path+'test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1b62da",
   "metadata": {},
   "source": [
    "# Random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38a52f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def TL_train_Random(Total,Batch,train,valid,test,Train_param_path,RESULT_path,Sampled_img_path):\n",
    "    \n",
    "    for total in Total:\n",
    "        print(total)\n",
    "\n",
    "        num_classes = 4\n",
    "        num_epochs = 100\n",
    "        train_layer=5\n",
    "        batch=Batch\n",
    "        patience=10\n",
    "\n",
    "        model = get_model_instance_segmentation(num_classes,train_layer)\n",
    "        device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "        # move model to the right device\n",
    "        model.to(device)\n",
    "        model.load_state_dict(torch.load('D:/OBJ_PAPER/model_param/model_fasterrcnn_bach5_p10_50_param.pt'))\n",
    "\n",
    "        # parameters\n",
    "        params = [p for p in model.parameters() if p.requires_grad]\n",
    "        optimizer = torch.optim.Adam(params, lr=0.0001)\n",
    "\n",
    "        iteration = 0    \n",
    "\n",
    "        RESULT=pd.DataFrame()\n",
    "        Sampled_img=pd.DataFrame()\n",
    "\n",
    "        #모델 저장 \n",
    "        train_param_path=Train_param_path.format(total)\n",
    "\n",
    "        #data reload\n",
    "        train_data_loader=data_load(train)\n",
    "        valid_data_loader=data_load(valid)\n",
    "        test_data_loader=data_load(test)\n",
    "\n",
    "\n",
    "\n",
    "        while len(Sampled_img)<total:\n",
    "\n",
    "            if len(Sampled_img)+batch>total:\n",
    "                batch=total-len(Sampled_img)\n",
    "\n",
    "            sampled,train_rest=random_sampling(train,batch)\n",
    "            Sampled_img=Sampled_img.append(sampled,ignore_index=True)\n",
    "            sample_data_loader=data_load(Sampled_img)\n",
    "            \n",
    "            Sampled_img['iter']=iteration\n",
    "\n",
    "            #sample 제외한 나머지 train 데이터\n",
    "            train=train_rest\n",
    "\n",
    "            iteration += 1\n",
    "\n",
    "            model.train()\n",
    "            not_save_count=0\n",
    "            st = time.time()\n",
    "\n",
    "            #평균 loss\n",
    "            avg_train_loss=[]\n",
    "            avg_valid_loss=[]\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "\n",
    "                # 모델이 학습되는 동안 trainning loss를 track\n",
    "                train_losses = []\n",
    "                # 모델이 학습되는 동안 validation loss를 track\n",
    "                valid_losses = []\n",
    "                \n",
    "                st = time.time()\n",
    "                for imgs, annotations in sample_data_loader:\n",
    "\n",
    "                    imgs = list(img.to(device) for img in imgs)\n",
    "                    annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n",
    "                    loss_dict = model(imgs, annotations)\n",
    "                    #batch size=10, 10개 loss 각각 도출\n",
    "                    losses = sum(loss for loss in loss_dict.values())\n",
    "                    train_losses.append(losses.item())       \n",
    "                    optimizer.zero_grad()\n",
    "                    losses.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                 #이미지 한장당 평균 loss\n",
    "                avg_train_loss.append(np.mean(train_losses).round(5))\n",
    "\n",
    "                #validation, early_stop, save weights\n",
    "                with torch.no_grad():\n",
    "\n",
    "                    for im, annot in valid_data_loader:\n",
    "                        im = list(img.to(device) for img in im)\n",
    "                        annot = [{k: v.to(device) for k, v in t.items()} for t in annot]\n",
    "                        val_loss_dict = model(im, annot)\n",
    "                        val_losses = sum(val_loss for val_loss in val_loss_dict.values())\n",
    "                        valid_losses.append(val_losses.item())\n",
    "\n",
    "                    epoch_val_loss=np.mean(valid_losses).round(5)\n",
    "                    avg_valid_loss.append(epoch_val_loss)  \n",
    "\n",
    "                fi = time.time()     \n",
    "                print('epoch:',epoch,'train_loss: ',np.mean(train_losses).round(5),'validation loss : ',np.mean(valid_losses).round(5),'time',fi-st)\n",
    "\n",
    "\n",
    "                min_val_loss=np.min(avg_valid_loss)\n",
    "                if min_val_loss>=epoch_val_loss:\n",
    "\n",
    "                    torch.save(model.state_dict(),train_param_path)\n",
    "                    not_save_count=0\n",
    "                    print('epoch:',epoch,'save model')\n",
    "\n",
    "                else:\n",
    "                    not_save_count+=1\n",
    "                    model.load_state_dict(torch.load(train_param_path))\n",
    "                    if not_save_count>=patience:\n",
    "                        print('no more training')\n",
    "                        break\n",
    "\n",
    "\n",
    "\n",
    "            fi = time.time()     \n",
    "            print('iteration:',iteration,'train_loss: ',np.mean(train_losses).round(5),'time',fi-st)\n",
    "            print('sample num:',len(Sampled_img))\n",
    "            model.load_state_dict(torch.load(train_param_path))\n",
    "            \n",
    "            result_batch=result_RPA(test_data_loader,model,train_param_path,iteration)\n",
    "            RESULT=RESULT.append(result_batch,ignore_index=True)\n",
    "\n",
    "        RESULT.to_csv(RESULT_path.format(total),index=False)   \n",
    "        Sampled_img.to_csv(Sampled_img_path.format(total),index=False)   \n",
    "        \n",
    "        return RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04ae82bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348\n",
      "epoch: 0 train_loss:  0.2475 validation loss :  0.23735 time 14.424647331237793\n",
      "epoch: 0 save model\n",
      "epoch: 1 train_loss:  0.1579 validation loss :  0.24508 time 9.294165849685669\n",
      "epoch: 2 train_loss:  0.13379 validation loss :  0.25864 time 9.277958393096924\n",
      "epoch: 3 train_loss:  0.12885 validation loss :  0.25232 time 9.281796932220459\n",
      "epoch: 4 train_loss:  0.13061 validation loss :  0.25683 time 9.270211935043335\n",
      "epoch: 5 train_loss:  0.13224 validation loss :  0.2763 time 9.292159080505371\n",
      "epoch: 6 train_loss:  0.12996 validation loss :  0.26678 time 9.30854320526123\n",
      "epoch: 7 train_loss:  0.13261 validation loss :  0.26575 time 9.252346277236938\n",
      "epoch: 8 train_loss:  0.13319 validation loss :  0.27769 time 9.25153112411499\n",
      "epoch: 9 train_loss:  0.13153 validation loss :  0.27885 time 9.330727815628052\n",
      "epoch: 10 train_loss:  0.12981 validation loss :  0.27213 time 9.254356622695923\n",
      "no more training\n",
      "iteration: 1 train_loss:  0.12981 time 9.395301818847656\n",
      "sample num: 30\n",
      "confidence= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:09<00:00, 10.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.23684, 0.81609, 0.62201]\n",
      "recall [0.50943, 0.98611, 0.83333]\n",
      "[[0.50943, 0.98611, 0.83333]] \n",
      " [[0.23684, 0.81609, 0.62201]] \n",
      " [[0.32335, 0.89308, 0.71233]]\n",
      "epoch: 0 train_loss:  0.21145 validation loss :  0.23762 time 14.491578578948975\n",
      "epoch: 0 save model\n",
      "epoch: 1 train_loss:  0.18689 validation loss :  0.21155 time 14.253196477890015\n",
      "epoch: 1 save model\n",
      "epoch: 2 train_loss:  0.15151 validation loss :  0.19635 time 14.250759840011597\n",
      "epoch: 2 save model\n",
      "epoch: 3 train_loss:  0.12409 validation loss :  0.18869 time 14.264440298080444\n",
      "epoch: 3 save model\n",
      "epoch: 4 train_loss:  0.10867 validation loss :  0.19942 time 14.520627975463867\n",
      "epoch: 5 train_loss:  0.10239 validation loss :  0.22365 time 14.300076484680176\n",
      "epoch: 6 train_loss:  0.11673 validation loss :  0.19913 time 14.25854229927063\n",
      "epoch: 7 train_loss:  0.11063 validation loss :  0.21187 time 14.225983381271362\n",
      "epoch: 8 train_loss:  0.1187 validation loss :  0.20796 time 14.203076839447021\n",
      "epoch: 9 train_loss:  0.10573 validation loss :  0.19103 time 14.200487852096558\n",
      "epoch: 10 train_loss:  0.11361 validation loss :  0.1905 time 14.240536212921143\n",
      "epoch: 11 train_loss:  0.10831 validation loss :  0.20908 time 14.21742033958435\n",
      "epoch: 12 train_loss:  0.10257 validation loss :  0.1836 time 14.230602741241455\n",
      "epoch: 12 save model\n",
      "epoch: 13 train_loss:  0.10125 validation loss :  0.18158 time 14.218993186950684\n",
      "epoch: 13 save model\n",
      "epoch: 14 train_loss:  0.08801 validation loss :  0.20167 time 14.26007080078125\n",
      "epoch: 15 train_loss:  0.08381 validation loss :  0.20064 time 14.281781435012817\n",
      "epoch: 16 train_loss:  0.08327 validation loss :  0.1845 time 14.316544532775879\n",
      "epoch: 17 train_loss:  0.08618 validation loss :  0.20516 time 14.245842218399048\n",
      "epoch: 18 train_loss:  0.08617 validation loss :  0.18233 time 14.333910703659058\n",
      "epoch: 19 train_loss:  0.08276 validation loss :  0.18838 time 14.260561466217041\n",
      "epoch: 20 train_loss:  0.08706 validation loss :  0.18889 time 14.312341690063477\n",
      "epoch: 21 train_loss:  0.08513 validation loss :  0.20046 time 14.290749788284302\n",
      "epoch: 22 train_loss:  0.09132 validation loss :  0.17839 time 14.347278118133545\n",
      "epoch: 22 save model\n",
      "epoch: 23 train_loss:  0.08751 validation loss :  0.19437 time 14.263511896133423\n",
      "epoch: 24 train_loss:  0.08117 validation loss :  0.21163 time 14.342549800872803\n",
      "epoch: 25 train_loss:  0.08331 validation loss :  0.20144 time 14.284926652908325\n",
      "epoch: 26 train_loss:  0.0797 validation loss :  0.21698 time 14.255370140075684\n",
      "epoch: 27 train_loss:  0.08101 validation loss :  0.18637 time 14.303808450698853\n",
      "epoch: 28 train_loss:  0.08325 validation loss :  0.20743 time 14.295435905456543\n",
      "epoch: 29 train_loss:  0.08216 validation loss :  0.18283 time 14.306737184524536\n",
      "epoch: 30 train_loss:  0.08226 validation loss :  0.20739 time 14.305800437927246\n",
      "epoch: 31 train_loss:  0.08405 validation loss :  0.18943 time 14.293097257614136\n",
      "epoch: 32 train_loss:  0.08237 validation loss :  0.23598 time 14.309239625930786\n",
      "no more training\n",
      "iteration: 2 train_loss:  0.08237 time 14.450244426727295\n",
      "sample num: 60\n",
      "confidence= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.58537, 0.84146, 0.86747]\n",
      "recall [0.90566, 0.95833, 0.92308]\n",
      "[[0.90566, 0.95833, 0.92308]] \n",
      " [[0.58537, 0.84146, 0.86747]] \n",
      " [[0.71111, 0.8961, 0.89441]]\n",
      "epoch: 0 train_loss:  0.16966 validation loss :  0.42624 time 19.456435918807983\n",
      "epoch: 0 save model\n",
      "epoch: 1 train_loss:  0.22636 validation loss :  0.28981 time 19.454981327056885\n",
      "epoch: 1 save model\n",
      "epoch: 2 train_loss:  0.18045 validation loss :  0.18257 time 19.271204948425293\n",
      "epoch: 2 save model\n",
      "epoch: 3 train_loss:  0.13231 validation loss :  0.17273 time 19.230036973953247\n",
      "epoch: 3 save model\n",
      "epoch: 4 train_loss:  0.11778 validation loss :  0.18093 time 19.25792169570923\n",
      "epoch: 5 train_loss:  0.11199 validation loss :  0.16535 time 19.25409960746765\n",
      "epoch: 5 save model\n",
      "epoch: 6 train_loss:  0.09204 validation loss :  0.16585 time 19.350342750549316\n",
      "epoch: 7 train_loss:  0.09406 validation loss :  0.1742 time 19.405197143554688\n",
      "epoch: 8 train_loss:  0.08702 validation loss :  0.17045 time 19.27405023574829\n",
      "epoch: 9 train_loss:  0.08852 validation loss :  0.17621 time 19.345337867736816\n",
      "epoch: 10 train_loss:  0.08748 validation loss :  0.17113 time 19.33820915222168\n",
      "epoch: 11 train_loss:  0.08757 validation loss :  0.17665 time 19.378854274749756\n",
      "epoch: 12 train_loss:  0.09117 validation loss :  0.17305 time 19.38457465171814\n",
      "epoch: 13 train_loss:  0.0911 validation loss :  0.18252 time 19.40616512298584\n",
      "epoch: 14 train_loss:  0.08999 validation loss :  0.16332 time 19.340914726257324\n",
      "epoch: 14 save model\n",
      "epoch: 15 train_loss:  0.09061 validation loss :  0.17263 time 19.771708726882935\n",
      "epoch: 16 train_loss:  0.08781 validation loss :  0.18298 time 19.462005376815796\n",
      "epoch: 17 train_loss:  0.09071 validation loss :  0.19655 time 19.41631579399109\n",
      "epoch: 18 train_loss:  0.08984 validation loss :  0.18574 time 19.438931226730347\n",
      "epoch: 19 train_loss:  0.08809 validation loss :  0.1931 time 19.43935227394104\n",
      "epoch: 20 train_loss:  0.09003 validation loss :  0.17466 time 19.358182668685913\n",
      "epoch: 21 train_loss:  0.09059 validation loss :  0.18925 time 19.385244607925415\n",
      "epoch: 22 train_loss:  0.0913 validation loss :  0.18694 time 19.37479853630066\n",
      "epoch: 23 train_loss:  0.09046 validation loss :  0.186 time 19.405165672302246\n",
      "epoch: 24 train_loss:  0.08929 validation loss :  0.18426 time 19.344223022460938\n",
      "no more training\n",
      "iteration: 3 train_loss:  0.08929 time 19.489531755447388\n",
      "sample num: 90\n",
      "confidence= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.58824, 0.93333, 0.66522]\n",
      "recall [0.75472, 0.97222, 0.98077]\n",
      "[[0.75472, 0.97222, 0.98077]] \n",
      " [[0.58824, 0.93333, 0.66522]] \n",
      " [[0.66116, 0.95238, 0.79275]]\n",
      "epoch: 0 train_loss:  0.13768 validation loss :  0.20464 time 24.56903100013733\n",
      "epoch: 0 save model\n",
      "epoch: 1 train_loss:  0.16053 validation loss :  0.15944 time 24.32399559020996\n",
      "epoch: 1 save model\n",
      "epoch: 2 train_loss:  0.1121 validation loss :  0.15863 time 24.294668674468994\n",
      "epoch: 2 save model\n",
      "epoch: 3 train_loss:  0.08978 validation loss :  0.14753 time 24.32969093322754\n",
      "epoch: 3 save model\n",
      "epoch: 4 train_loss:  0.08322 validation loss :  0.16302 time 24.34327459335327\n",
      "epoch: 5 train_loss:  0.08214 validation loss :  0.1403 time 24.324382305145264\n",
      "epoch: 5 save model\n",
      "epoch: 6 train_loss:  0.08367 validation loss :  0.15993 time 24.43139672279358\n",
      "epoch: 7 train_loss:  0.07783 validation loss :  0.15689 time 24.30618977546692\n",
      "epoch: 8 train_loss:  0.07926 validation loss :  0.14875 time 24.43636393547058\n",
      "epoch: 9 train_loss:  0.08683 validation loss :  0.16693 time 24.376896381378174\n",
      "epoch: 10 train_loss:  0.07928 validation loss :  0.14864 time 24.471938371658325\n",
      "epoch: 11 train_loss:  0.07917 validation loss :  0.15248 time 24.462234497070312\n",
      "epoch: 12 train_loss:  0.08246 validation loss :  0.14917 time 24.361334323883057\n",
      "epoch: 13 train_loss:  0.08011 validation loss :  0.14533 time 24.338687896728516\n",
      "epoch: 14 train_loss:  0.08151 validation loss :  0.1569 time 24.386613845825195\n",
      "epoch: 15 train_loss:  0.08116 validation loss :  0.1537 time 24.338805198669434\n",
      "no more training\n",
      "iteration: 4 train_loss:  0.08116 time 24.484012365341187\n",
      "sample num: 120\n",
      "confidence= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.67143, 0.91026, 0.85965]\n",
      "recall [0.88679, 0.98611, 0.94231]\n",
      "[[0.88679, 0.98611, 0.94231]] \n",
      " [[0.67143, 0.91026, 0.85965]] \n",
      " [[0.76423, 0.94667, 0.89908]]\n",
      "epoch: 0 train_loss:  0.1069 validation loss :  0.16798 time 29.341440200805664\n",
      "epoch: 0 save model\n",
      "epoch: 1 train_loss:  0.1214 validation loss :  0.16235 time 29.23193907737732\n",
      "epoch: 1 save model\n",
      "epoch: 2 train_loss:  0.09824 validation loss :  0.13969 time 29.371745586395264\n",
      "epoch: 2 save model\n",
      "epoch: 3 train_loss:  0.08018 validation loss :  0.13169 time 29.311859369277954\n",
      "epoch: 3 save model\n",
      "epoch: 4 train_loss:  0.07005 validation loss :  0.13633 time 29.25084114074707\n",
      "epoch: 5 train_loss:  0.07049 validation loss :  0.1324 time 29.196024179458618\n",
      "epoch: 6 train_loss:  0.07133 validation loss :  0.1399 time 29.30858874320984\n",
      "epoch: 7 train_loss:  0.07157 validation loss :  0.13727 time 29.232372045516968\n",
      "epoch: 8 train_loss:  0.07473 validation loss :  0.14703 time 29.293415784835815\n",
      "epoch: 9 train_loss:  0.07341 validation loss :  0.13988 time 29.245256900787354\n",
      "epoch: 10 train_loss:  0.07601 validation loss :  0.13643 time 29.50626826286316\n",
      "epoch: 11 train_loss:  0.07037 validation loss :  0.12888 time 29.32704210281372\n",
      "epoch: 11 save model\n",
      "epoch: 12 train_loss:  0.07655 validation loss :  0.12732 time 29.285266160964966\n",
      "epoch: 12 save model\n",
      "epoch: 13 train_loss:  0.08638 validation loss :  0.13273 time 29.321125984191895\n",
      "epoch: 14 train_loss:  0.07438 validation loss :  0.13381 time 29.331286907196045\n",
      "epoch: 15 train_loss:  0.0809 validation loss :  0.13062 time 29.387825965881348\n",
      "epoch: 16 train_loss:  0.07807 validation loss :  0.1269 time 29.34677743911743\n",
      "epoch: 16 save model\n",
      "epoch: 17 train_loss:  0.06822 validation loss :  0.13537 time 29.36808729171753\n",
      "epoch: 18 train_loss:  0.06923 validation loss :  0.13226 time 29.362753868103027\n",
      "epoch: 19 train_loss:  0.0683 validation loss :  0.12998 time 29.326175689697266\n",
      "epoch: 20 train_loss:  0.07393 validation loss :  0.13316 time 29.318535566329956\n",
      "epoch: 21 train_loss:  0.0681 validation loss :  0.13682 time 29.341466903686523\n",
      "epoch: 22 train_loss:  0.0692 validation loss :  0.14079 time 29.41291069984436\n",
      "epoch: 23 train_loss:  0.07099 validation loss :  0.13229 time 29.30599546432495\n",
      "epoch: 24 train_loss:  0.06864 validation loss :  0.13821 time 29.304933786392212\n",
      "epoch: 25 train_loss:  0.06941 validation loss :  0.13702 time 29.3163959980011\n",
      "epoch: 26 train_loss:  0.09582 validation loss :  0.17277 time 29.325721502304077\n",
      "no more training\n",
      "iteration: 5 train_loss:  0.09582 time 29.47178864479065\n",
      "sample num: 150\n",
      "confidence= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.82692, 0.83529, 0.78238]\n",
      "recall [0.81132, 0.98611, 0.96795]\n",
      "[[0.81132, 0.98611, 0.96795]] \n",
      " [[0.82692, 0.83529, 0.78238]] \n",
      " [[0.81905, 0.90446, 0.86533]]\n",
      "epoch: 0 train_loss:  0.09484 validation loss :  0.15122 time 34.21465182304382\n",
      "epoch: 0 save model\n",
      "epoch: 1 train_loss:  0.09759 validation loss :  0.13574 time 34.31721901893616\n",
      "epoch: 1 save model\n",
      "epoch: 2 train_loss:  0.08415 validation loss :  0.11786 time 34.27867150306702\n",
      "epoch: 2 save model\n",
      "epoch: 3 train_loss:  0.0699 validation loss :  0.12604 time 34.249980211257935\n",
      "epoch: 4 train_loss:  0.07125 validation loss :  0.12418 time 34.25363326072693\n",
      "epoch: 5 train_loss:  0.06959 validation loss :  0.12868 time 34.17219877243042\n",
      "epoch: 6 train_loss:  0.07321 validation loss :  0.14017 time 34.337563276290894\n",
      "epoch: 7 train_loss:  0.0709 validation loss :  0.11608 time 34.31079339981079\n",
      "epoch: 7 save model\n",
      "epoch: 8 train_loss:  0.07062 validation loss :  0.12972 time 34.397955656051636\n",
      "epoch: 9 train_loss:  0.07168 validation loss :  0.12995 time 34.464338541030884\n",
      "epoch: 10 train_loss:  0.0723 validation loss :  0.11374 time 34.25835108757019\n",
      "epoch: 10 save model\n",
      "epoch: 11 train_loss:  0.06469 validation loss :  0.12826 time 34.17867970466614\n",
      "epoch: 12 train_loss:  0.06342 validation loss :  0.12184 time 34.22733950614929\n",
      "epoch: 13 train_loss:  0.06619 validation loss :  0.12833 time 34.28249430656433\n",
      "epoch: 14 train_loss:  0.06629 validation loss :  0.13011 time 34.223135471343994\n",
      "epoch: 15 train_loss:  0.06608 validation loss :  0.11714 time 34.21407437324524\n",
      "epoch: 16 train_loss:  0.0643 validation loss :  0.11054 time 34.17492151260376\n",
      "epoch: 16 save model\n",
      "epoch: 17 train_loss:  0.06448 validation loss :  0.1347 time 34.3432514667511\n",
      "epoch: 18 train_loss:  0.06333 validation loss :  0.12963 time 34.25712823867798\n",
      "epoch: 19 train_loss:  0.06455 validation loss :  0.12716 time 34.261536836624146\n",
      "epoch: 20 train_loss:  0.06465 validation loss :  0.11627 time 34.284647941589355\n",
      "epoch: 21 train_loss:  0.06197 validation loss :  0.12116 time 34.364880323410034\n",
      "epoch: 22 train_loss:  0.06602 validation loss :  0.12841 time 34.20820641517639\n",
      "epoch: 23 train_loss:  0.06516 validation loss :  0.11343 time 34.23042345046997\n",
      "epoch: 24 train_loss:  0.06549 validation loss :  0.12674 time 34.24842095375061\n",
      "epoch: 25 train_loss:  0.0651 validation loss :  0.13381 time 34.29301953315735\n",
      "epoch: 26 train_loss:  0.06425 validation loss :  0.12057 time 34.201082706451416\n",
      "no more training\n",
      "iteration: 6 train_loss:  0.06425 time 34.348246335983276\n",
      "sample num: 180\n",
      "confidence= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.81481, 0.92208, 0.81622]\n",
      "recall [0.83019, 0.98611, 0.96795]\n",
      "[[0.83019, 0.98611, 0.96795]] \n",
      " [[0.81481, 0.92208, 0.81622]] \n",
      " [[0.82243, 0.95302, 0.88563]]\n",
      "epoch: 0 train_loss:  0.08968 validation loss :  0.22091 time 39.337074518203735\n",
      "epoch: 0 save model\n",
      "epoch: 1 train_loss:  0.15323 validation loss :  0.13118 time 39.26493763923645\n",
      "epoch: 1 save model\n",
      "epoch: 2 train_loss:  0.10163 validation loss :  0.12432 time 39.26778197288513\n",
      "epoch: 2 save model\n",
      "epoch: 3 train_loss:  0.07617 validation loss :  0.11979 time 39.278536319732666\n",
      "epoch: 3 save model\n",
      "epoch: 4 train_loss:  0.06465 validation loss :  0.12532 time 39.28949785232544\n",
      "epoch: 5 train_loss:  0.06506 validation loss :  0.1235 time 39.261900901794434\n",
      "epoch: 6 train_loss:  0.0635 validation loss :  0.12122 time 39.2964506149292\n",
      "epoch: 7 train_loss:  0.0649 validation loss :  0.12065 time 39.313679933547974\n",
      "epoch: 8 train_loss:  0.06584 validation loss :  0.13203 time 39.33537530899048\n",
      "epoch: 9 train_loss:  0.06724 validation loss :  0.11906 time 39.29310488700867\n",
      "epoch: 9 save model\n",
      "epoch: 10 train_loss:  0.06385 validation loss :  0.12876 time 39.170485973358154\n",
      "epoch: 11 train_loss:  0.06238 validation loss :  0.12584 time 39.231417655944824\n",
      "epoch: 12 train_loss:  0.06324 validation loss :  0.12116 time 39.25411605834961\n",
      "epoch: 13 train_loss:  0.06557 validation loss :  0.12217 time 39.50460386276245\n",
      "epoch: 14 train_loss:  0.06254 validation loss :  0.12368 time 39.24406337738037\n",
      "epoch: 15 train_loss:  0.06639 validation loss :  0.12472 time 39.23865795135498\n",
      "epoch: 16 train_loss:  0.06475 validation loss :  0.1289 time 39.220194578170776\n",
      "epoch: 17 train_loss:  0.06433 validation loss :  0.13432 time 41.30084443092346\n",
      "epoch: 18 train_loss:  0.06533 validation loss :  0.13272 time 40.25479555130005\n",
      "epoch: 19 train_loss:  0.06594 validation loss :  0.13854 time 40.05966019630432\n",
      "no more training\n",
      "iteration: 7 train_loss:  0.06594 time 40.208144426345825\n",
      "sample num: 210\n",
      "confidence= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.52809, 0.98571, 0.87647]\n",
      "recall [0.88679, 0.95833, 0.95513]\n",
      "[[0.88679, 0.95833, 0.95513]] \n",
      " [[0.52809, 0.98571, 0.87647]] \n",
      " [[0.66197, 0.97183, 0.91411]]\n",
      "epoch: 0 train_loss:  0.09679 validation loss :  0.1857 time 44.552201986312866\n",
      "epoch: 0 save model\n",
      "epoch: 1 train_loss:  0.12529 validation loss :  0.16106 time 44.15109658241272\n",
      "epoch: 1 save model\n",
      "epoch: 2 train_loss:  0.10276 validation loss :  0.12278 time 44.20925235748291\n",
      "epoch: 2 save model\n",
      "epoch: 3 train_loss:  0.07788 validation loss :  0.1258 time 44.34557795524597\n",
      "epoch: 4 train_loss:  0.07766 validation loss :  0.12194 time 44.41262125968933\n",
      "epoch: 4 save model\n",
      "epoch: 5 train_loss:  0.06543 validation loss :  0.12254 time 44.3164803981781\n",
      "epoch: 6 train_loss:  0.06645 validation loss :  0.13112 time 44.27968168258667\n",
      "epoch: 7 train_loss:  0.0691 validation loss :  0.13005 time 44.32800054550171\n",
      "epoch: 8 train_loss:  0.06849 validation loss :  0.13142 time 44.24375605583191\n",
      "epoch: 9 train_loss:  0.06958 validation loss :  0.12924 time 44.43413972854614\n",
      "epoch: 10 train_loss:  0.06896 validation loss :  0.13579 time 44.40151619911194\n",
      "epoch: 11 train_loss:  0.07085 validation loss :  0.13712 time 44.3906455039978\n",
      "epoch: 12 train_loss:  0.07249 validation loss :  0.12158 time 44.25541806221008\n",
      "epoch: 12 save model\n",
      "epoch: 13 train_loss:  0.07063 validation loss :  0.14421 time 44.25047755241394\n",
      "epoch: 14 train_loss:  0.06629 validation loss :  0.12887 time 44.197951316833496\n",
      "epoch: 15 train_loss:  0.06688 validation loss :  0.12411 time 44.193371295928955\n",
      "epoch: 16 train_loss:  0.06928 validation loss :  0.13236 time 44.25189137458801\n",
      "epoch: 17 train_loss:  0.06699 validation loss :  0.13873 time 44.21675395965576\n",
      "epoch: 18 train_loss:  0.06712 validation loss :  0.12133 time 44.30091571807861\n",
      "epoch: 18 save model\n",
      "epoch: 19 train_loss:  0.06435 validation loss :  0.12399 time 44.35557413101196\n",
      "epoch: 20 train_loss:  0.06468 validation loss :  0.13227 time 44.380921602249146\n",
      "epoch: 21 train_loss:  0.06408 validation loss :  0.13656 time 44.262067794799805\n",
      "epoch: 22 train_loss:  0.0612 validation loss :  0.13467 time 44.27914786338806\n",
      "epoch: 23 train_loss:  0.06276 validation loss :  0.14244 time 44.25296449661255\n",
      "epoch: 24 train_loss:  0.06449 validation loss :  0.13848 time 44.27357625961304\n",
      "epoch: 25 train_loss:  0.06424 validation loss :  0.14536 time 44.39971590042114\n",
      "epoch: 26 train_loss:  0.06359 validation loss :  0.1586 time 44.28135418891907\n",
      "epoch: 27 train_loss:  0.0661 validation loss :  0.13302 time 44.28113889694214\n",
      "epoch: 28 train_loss:  0.06522 validation loss :  0.13878 time 44.34512424468994\n",
      "no more training\n",
      "iteration: 8 train_loss:  0.06522 time 44.492549896240234\n",
      "sample num: 240\n",
      "confidence= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.8, 0.86585, 0.87356]\n",
      "recall [0.83019, 0.98611, 0.97436]\n",
      "[[0.83019, 0.98611, 0.97436]] \n",
      " [[0.8, 0.86585, 0.87356]] \n",
      " [[0.81482, 0.92208, 0.92121]]\n",
      "epoch: 0 train_loss:  0.08456 validation loss :  0.20508 time 49.23236560821533\n",
      "epoch: 0 save model\n",
      "epoch: 1 train_loss:  0.10941 validation loss :  0.14219 time 49.15962743759155\n",
      "epoch: 1 save model\n",
      "epoch: 2 train_loss:  0.07245 validation loss :  0.11356 time 50.0176887512207\n",
      "epoch: 2 save model\n",
      "epoch: 3 train_loss:  0.06321 validation loss :  0.12773 time 49.20708966255188\n",
      "epoch: 4 train_loss:  0.06019 validation loss :  0.12831 time 49.236135959625244\n",
      "epoch: 5 train_loss:  0.06215 validation loss :  0.12388 time 49.21811032295227\n",
      "epoch: 6 train_loss:  0.06203 validation loss :  0.12404 time 49.28965187072754\n",
      "epoch: 7 train_loss:  0.06248 validation loss :  0.11834 time 49.24846339225769\n",
      "epoch: 8 train_loss:  0.06362 validation loss :  0.11895 time 49.27637076377869\n",
      "epoch: 9 train_loss:  0.06369 validation loss :  0.12452 time 49.18181324005127\n",
      "epoch: 10 train_loss:  0.06651 validation loss :  0.11903 time 49.231372356414795\n",
      "epoch: 11 train_loss:  0.06192 validation loss :  0.11713 time 49.26959013938904\n",
      "epoch: 12 train_loss:  0.0667 validation loss :  0.12743 time 49.18521332740784\n",
      "no more training\n",
      "iteration: 9 train_loss:  0.0667 time 49.33403038978577\n",
      "sample num: 270\n",
      "confidence= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.6, 0.84524, 0.80105]\n",
      "recall [0.90566, 0.98611, 0.98077]\n",
      "[[0.90566, 0.98611, 0.98077]] \n",
      " [[0.6, 0.84524, 0.80105]] \n",
      " [[0.7218, 0.91026, 0.88185]]\n",
      "epoch: 0 train_loss:  0.07334 validation loss :  0.14057 time 54.1659140586853\n",
      "epoch: 0 save model\n",
      "epoch: 1 train_loss:  0.07803 validation loss :  0.12532 time 54.174614667892456\n",
      "epoch: 1 save model\n",
      "epoch: 2 train_loss:  0.0615 validation loss :  0.1122 time 54.16770958900452\n",
      "epoch: 2 save model\n",
      "epoch: 3 train_loss:  0.05191 validation loss :  0.11244 time 55.52359986305237\n",
      "epoch: 4 train_loss:  0.0521 validation loss :  0.13632 time 55.487377405166626\n",
      "epoch: 5 train_loss:  0.05182 validation loss :  0.11482 time 54.257591247558594\n",
      "epoch: 6 train_loss:  0.05419 validation loss :  0.12229 time 54.55371165275574\n",
      "epoch: 7 train_loss:  0.05324 validation loss :  0.12145 time 54.19804334640503\n",
      "epoch: 8 train_loss:  0.05546 validation loss :  0.12159 time 54.189040422439575\n",
      "epoch: 9 train_loss:  0.05351 validation loss :  0.12307 time 54.18117594718933\n",
      "epoch: 10 train_loss:  0.05423 validation loss :  0.11336 time 54.242961406707764\n",
      "epoch: 11 train_loss:  0.05771 validation loss :  0.12082 time 54.19149851799011\n",
      "epoch: 12 train_loss:  0.05525 validation loss :  0.12713 time 54.309165477752686\n",
      "no more training\n",
      "iteration: 10 train_loss:  0.05525 time 54.46165108680725\n",
      "sample num: 300\n",
      "confidence= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.84906, 0.8875, 0.86705]\n",
      "recall [0.84906, 0.98611, 0.96154]\n",
      "[[0.84906, 0.98611, 0.96154]] \n",
      " [[0.84906, 0.8875, 0.86705]] \n",
      " [[0.84906, 0.93421, 0.91185]]\n",
      "epoch: 0 train_loss:  0.06475 validation loss :  0.13215 time 59.16971802711487\n",
      "epoch: 0 save model\n",
      "epoch: 1 train_loss:  0.09411 validation loss :  0.13469 time 59.18836069107056\n",
      "epoch: 2 train_loss:  0.06378 validation loss :  0.11454 time 59.15784311294556\n",
      "epoch: 2 save model\n",
      "epoch: 3 train_loss:  0.05132 validation loss :  0.12174 time 59.11838340759277\n",
      "epoch: 4 train_loss:  0.05429 validation loss :  0.12002 time 59.183207273483276\n",
      "epoch: 5 train_loss:  0.05441 validation loss :  0.12095 time 59.105998516082764\n",
      "epoch: 6 train_loss:  0.05481 validation loss :  0.11801 time 59.17156434059143\n",
      "epoch: 7 train_loss:  0.05423 validation loss :  0.14034 time 59.139240741729736\n",
      "epoch: 8 train_loss:  0.05452 validation loss :  0.12476 time 59.05493974685669\n",
      "epoch: 9 train_loss:  0.06046 validation loss :  0.11604 time 59.219871282577515\n",
      "epoch: 10 train_loss:  0.05884 validation loss :  0.15564 time 59.118654012680054\n",
      "epoch: 11 train_loss:  0.0544 validation loss :  0.12158 time 59.12291669845581\n",
      "epoch: 12 train_loss:  0.05638 validation loss :  0.12143 time 59.07965660095215\n",
      "no more training\n",
      "iteration: 11 train_loss:  0.05638 time 59.22505211830139\n",
      "sample num: 330\n",
      "confidence= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.78947, 0.92208, 0.83146]\n",
      "recall [0.84906, 0.98611, 0.94872]\n",
      "[[0.84906, 0.98611, 0.94872]] \n",
      " [[0.78947, 0.92208, 0.83146]] \n",
      " [[0.81818, 0.95302, 0.88623]]\n",
      "epoch: 0 train_loss:  0.06451 validation loss :  0.17308 time 62.35337543487549\n",
      "epoch: 0 save model\n",
      "epoch: 1 train_loss:  0.08341 validation loss :  0.12057 time 62.216511487960815\n",
      "epoch: 1 save model\n",
      "epoch: 2 train_loss:  0.0609 validation loss :  0.13094 time 62.09102010726929\n",
      "epoch: 3 train_loss:  0.05763 validation loss :  0.11969 time 61.98756217956543\n",
      "epoch: 3 save model\n",
      "epoch: 4 train_loss:  0.05291 validation loss :  0.14221 time 62.131627559661865\n",
      "epoch: 5 train_loss:  0.0509 validation loss :  0.14251 time 62.18280792236328\n",
      "epoch: 6 train_loss:  0.05351 validation loss :  0.14776 time 62.063246726989746\n",
      "epoch: 7 train_loss:  0.05358 validation loss :  0.12308 time 62.0254123210907\n",
      "epoch: 8 train_loss:  0.056 validation loss :  0.14879 time 62.04355263710022\n",
      "epoch: 9 train_loss:  0.05312 validation loss :  0.14098 time 62.10539722442627\n",
      "epoch: 10 train_loss:  0.05336 validation loss :  0.14388 time 62.15784931182861\n",
      "epoch: 11 train_loss:  0.05513 validation loss :  0.12068 time 62.02368140220642\n",
      "epoch: 12 train_loss:  0.05495 validation loss :  0.13133 time 62.128567934036255\n",
      "epoch: 13 train_loss:  0.05418 validation loss :  0.13166 time 62.04190373420715\n",
      "no more training\n",
      "iteration: 12 train_loss:  0.05418 time 62.18735098838806\n",
      "sample num: 348\n",
      "confidence= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.87755, 0.94667, 0.76263]\n",
      "recall [0.81132, 0.98611, 0.96795]\n",
      "[[0.81132, 0.98611, 0.96795]] \n",
      " [[0.87755, 0.94667, 0.76263]] \n",
      " [[0.84314, 0.96599, 0.85311]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>iteration</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.50943, 0.98611, 0.83333]]</td>\n",
       "      <td>[[0.23684, 0.81609, 0.62201]]</td>\n",
       "      <td>[[0.32335, 0.89308, 0.71233]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.90566, 0.95833, 0.92308]]</td>\n",
       "      <td>[[0.58537, 0.84146, 0.86747]]</td>\n",
       "      <td>[[0.71111, 0.8961, 0.89441]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.75472, 0.97222, 0.98077]]</td>\n",
       "      <td>[[0.58824, 0.93333, 0.66522]]</td>\n",
       "      <td>[[0.66116, 0.95238, 0.79275]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>[[0.88679, 0.98611, 0.94231]]</td>\n",
       "      <td>[[0.67143, 0.91026, 0.85965]]</td>\n",
       "      <td>[[0.76423, 0.94667, 0.89908]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>[[0.81132, 0.98611, 0.96795]]</td>\n",
       "      <td>[[0.82692, 0.83529, 0.78238]]</td>\n",
       "      <td>[[0.81905, 0.90446, 0.86533]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>6</td>\n",
       "      <td>[[0.83019, 0.98611, 0.96795]]</td>\n",
       "      <td>[[0.81481, 0.92208, 0.81622]]</td>\n",
       "      <td>[[0.82243, 0.95302, 0.88563]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5</td>\n",
       "      <td>7</td>\n",
       "      <td>[[0.88679, 0.95833, 0.95513]]</td>\n",
       "      <td>[[0.52809, 0.98571, 0.87647]]</td>\n",
       "      <td>[[0.66197, 0.97183, 0.91411]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5</td>\n",
       "      <td>8</td>\n",
       "      <td>[[0.83019, 0.98611, 0.97436]]</td>\n",
       "      <td>[[0.8, 0.86585, 0.87356]]</td>\n",
       "      <td>[[0.81482, 0.92208, 0.92121]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5</td>\n",
       "      <td>9</td>\n",
       "      <td>[[0.90566, 0.98611, 0.98077]]</td>\n",
       "      <td>[[0.6, 0.84524, 0.80105]]</td>\n",
       "      <td>[[0.7218, 0.91026, 0.88185]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>[[0.84906, 0.98611, 0.96154]]</td>\n",
       "      <td>[[0.84906, 0.8875, 0.86705]]</td>\n",
       "      <td>[[0.84906, 0.93421, 0.91185]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.5</td>\n",
       "      <td>11</td>\n",
       "      <td>[[0.84906, 0.98611, 0.94872]]</td>\n",
       "      <td>[[0.78947, 0.92208, 0.83146]]</td>\n",
       "      <td>[[0.81818, 0.95302, 0.88623]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.5</td>\n",
       "      <td>12</td>\n",
       "      <td>[[0.81132, 0.98611, 0.96795]]</td>\n",
       "      <td>[[0.87755, 0.94667, 0.76263]]</td>\n",
       "      <td>[[0.84314, 0.96599, 0.85311]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    confidence  iteration                         recall  \\\n",
       "0          0.5          1  [[0.50943, 0.98611, 0.83333]]   \n",
       "1          0.5          2  [[0.90566, 0.95833, 0.92308]]   \n",
       "2          0.5          3  [[0.75472, 0.97222, 0.98077]]   \n",
       "3          0.5          4  [[0.88679, 0.98611, 0.94231]]   \n",
       "4          0.5          5  [[0.81132, 0.98611, 0.96795]]   \n",
       "5          0.5          6  [[0.83019, 0.98611, 0.96795]]   \n",
       "6          0.5          7  [[0.88679, 0.95833, 0.95513]]   \n",
       "7          0.5          8  [[0.83019, 0.98611, 0.97436]]   \n",
       "8          0.5          9  [[0.90566, 0.98611, 0.98077]]   \n",
       "9          0.5         10  [[0.84906, 0.98611, 0.96154]]   \n",
       "10         0.5         11  [[0.84906, 0.98611, 0.94872]]   \n",
       "11         0.5         12  [[0.81132, 0.98611, 0.96795]]   \n",
       "\n",
       "                        precision                        f1_form  \n",
       "0   [[0.23684, 0.81609, 0.62201]]  [[0.32335, 0.89308, 0.71233]]  \n",
       "1   [[0.58537, 0.84146, 0.86747]]   [[0.71111, 0.8961, 0.89441]]  \n",
       "2   [[0.58824, 0.93333, 0.66522]]  [[0.66116, 0.95238, 0.79275]]  \n",
       "3   [[0.67143, 0.91026, 0.85965]]  [[0.76423, 0.94667, 0.89908]]  \n",
       "4   [[0.82692, 0.83529, 0.78238]]  [[0.81905, 0.90446, 0.86533]]  \n",
       "5   [[0.81481, 0.92208, 0.81622]]  [[0.82243, 0.95302, 0.88563]]  \n",
       "6   [[0.52809, 0.98571, 0.87647]]  [[0.66197, 0.97183, 0.91411]]  \n",
       "7       [[0.8, 0.86585, 0.87356]]  [[0.81482, 0.92208, 0.92121]]  \n",
       "8       [[0.6, 0.84524, 0.80105]]   [[0.7218, 0.91026, 0.88185]]  \n",
       "9    [[0.84906, 0.8875, 0.86705]]  [[0.84906, 0.93421, 0.91185]]  \n",
       "10  [[0.78947, 0.92208, 0.83146]]  [[0.81818, 0.95302, 0.88623]]  \n",
       "11  [[0.87755, 0.94667, 0.76263]]  [[0.84314, 0.96599, 0.85311]]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Total=[348]\n",
    "Batch=30\n",
    "train=train1\n",
    "valid=valid1\n",
    "test=test\n",
    "Train_param_path='D:/OBJ_PAPER/model_param/FRCN_itb_random1_batch30_total{}_param.pt'\n",
    "RESULT_path='D:/OBJ_PAPER/result/FRCN_itb_random1_batch30_total{}_result.csv'\n",
    "Sampled_img_path='D:/OBJ_PAPER/result/FRCN_itb_random1_batch30_total{}_sampled.csv'\n",
    "\n",
    "TL_train_Random(Total,Batch,train,valid,test,Train_param_path,RESULT_path,Sampled_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aabb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "Total=[100,200,300,343]\n",
    "Batch=30\n",
    "train=train2\n",
    "valid=valid2\n",
    "test=test\n",
    "train_param_path='D:/OBJ_PAPER/model_param/FRCN_itb_random2_batch30_total{}_param.pt'\n",
    "RESULT_path='D:/OBJ_PAPER/result/FRCN_random2_b30_total_{}_validation_p{}.csv'\n",
    "Sampled_img_path='D:/OBJ_PAPER/result/FRCN_random2_b30_total_{}_validation_p{}_sampled.csv'\n",
    "\n",
    "TL_train_Random(Total,Batch,train,valid,test,Train_param_path,RESULT_path,Sampled_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981c9eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Total=[100,200,300,343]\n",
    "Batch=30\n",
    "train=train3\n",
    "valid=valid3\n",
    "test=test\n",
    "train_param_path='D:/OBJ_PAPER/model_param/FRCN_itb_random3_batch30_total{}_param.pt'\n",
    "RESULT_path='D:/OBJ_PAPER/result/FRCN_random3_b30_total_{}_validation_p{}.csv'\n",
    "Sampled_img_path='D:/OBJ_PAPER/result/FRCN_random3_b30_total_{}_validation_p{}_sampled.csv'\n",
    "\n",
    "TL_train_Random(Total,Batch,train,valid,test,Train_param_path,RESULT_path,Sampled_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132f92c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
